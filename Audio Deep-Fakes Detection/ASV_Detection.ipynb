{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"ASV_Detection.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"vIU-4qp4OIMh","colab":{}},"source":["from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn import svm\n","from sklearn import metrics\n","import pandas as pd\n","import os\n","from matplotlib import pyplot as plt\n","import numpy as np\n","from pathlib import Path\n","import tensorflow as tf\n","import shutil\n","import librosa\n","from tqdm import tqdm_notebook\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import load_model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RBIa5k07fcfv"},"source":["# **SVM Approach**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XctZ2_xTNjaV","colab":{}},"source":["data = pd.read_csv('dataset_train_new.csv')\n","data = data.drop(['filename'],axis=1)\n","genre_list = data.iloc[:, -1]\n","encoder = LabelEncoder()\n","y_train = encoder.fit_transform(genre_list)\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n","\n","data = pd.read_csv('dataset_dev_new.csv')\n","data = data.drop(['filename'],axis=1)\n","genre_list = data.iloc[:, -1]\n","encoder = LabelEncoder()\n","y_dev = encoder.fit_transform(genre_list)\n","scaler = StandardScaler()\n","X_dev = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n","\n","data = pd.read_csv('dataset_eval_new.csv')\n","data = data.drop(['filename'],axis=1)\n","genre_list = data.iloc[:, -1]\n","encoder = LabelEncoder()\n","y_eval = encoder.fit_transform(genre_list)\n","scaler = StandardScaler()\n","X_eval = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ou3JpwX0OKjJ","colab":{"base_uri":"https://localhost:8080/","height":170},"outputId":"dc6fd5e8-e872-43ba-84be-1fe341716fbf"},"source":["clf = svm.SVC(kernel='rbf')\n","clf.fit(X_train, y_train)\n","y_pred = clf.predict(X_train)\n","print('Train')\n","print(\"Accuracy:\",metrics.accuracy_score(y_train, y_pred))\n","print()\n","y_pred = clf.predict(X_dev)\n","print('Dev')\n","print(\"Accuracy:\",metrics.accuracy_score(y_dev, y_pred))\n","print()\n","y_pred = clf.predict(X_eval)\n","print('Eval')\n","print(\"Accuracy:\",metrics.accuracy_score(y_eval, y_pred))\n","print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train\n","Accuracy: 0.9842169162282477\n","\n","Dev\n","Accuracy: 0.8535729037587774\n","\n","Eval\n","Accuracy: 0.8196755994358251\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"byfpOGLZfi-K"},"source":["# **CNN Approaches**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bXe1SnZrPv4Y","colab":{}},"source":["def small_cnn(input_shape = (256, 256, 1), lr = 1e-3, factor = 16):\n","    img_input = layers.Input(input_shape)\n","    X = layers.Conv2D(factor, 3, padding = 'same', activation = 'relu')(img_input)\n","    X = layers.MaxPooling2D(pool_size = (2, 2))(X)\n","    X = layers.Conv2D(factor*2, 3, padding = 'same', activation = 'relu')(X)\n","    X = layers.MaxPooling2D(pool_size = (2, 2))(X)\n","    X = layers.Conv2D(factor*4, 3, padding = 'same', activation = 'relu')(X)\n","    X = layers.MaxPooling2D(pool_size = (2, 2))(X)\n","    X = layers.Conv2D(factor*8, 3, padding = 'same', activation = 'relu')(X)\n","    X = layers.MaxPooling2D(pool_size = (2, 2))(X)\n","    X = layers.Conv2D(factor*16, 3, padding = 'same', activation = 'relu')(X)\n","    X = layers.MaxPooling2D(pool_size = (2, 2))(X)\n","    X = layers.Flatten()(X)\n","    X = layers.Dense(128, activation = 'relu')(X)\n","    X = layers.Dropout(rate=0.5)(X)\n","    X = layers.Dense(1)(X)\n","    X = layers.Activation('sigmoid', dtype='float32', name='predictions')(X)\n","    model = models.Model(inputs = img_input, outputs = X)\n","    model.compile(optimizer = Adam(lr), loss = 'binary_crossentropy', metrics = ['accuracy'])\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EUz9VsT9O7gk","colab":{"base_uri":"https://localhost:8080/","height":391},"outputId":"b16c6efa-fb4b-4d26-87a5-6ee7723d44a6"},"source":["for dataset,modelpath in zip(['mel_spec_256_crop_first','amp_plot_256_crop_first_negative',],['mel_spec_model.h5','amp_plot_model.h5']):\n","    batch_size = 64\n","    target_size = (256, 256)\n","    color_mode = 'grayscale'\n","    val_datagen = ImageDataGenerator(rescale=1/255)\n","    val_generator = val_datagen.flow_from_directory(f'{dataset}/dev/', target_size=target_size, batch_size=batch_size, class_mode='binary', color_mode=color_mode, classes = ['real','fake'])\n","    test_datagen = ImageDataGenerator(rescale=1/255)\n","    test_generator = test_datagen.flow_from_directory(f'{dataset}/eval/', target_size=target_size, batch_size=batch_size, class_mode='binary', color_mode=color_mode, classes = ['real','fake'])\n","    print()\n","    model = small_cnn()\n","    model.load_weights(modelpath)\n","    print(f'Model: {modelpath}')\n","    results = model.evaluate(val_generator,steps=2*len(val_generator),verbose=0)\n","    print('Development Set:')\n","    print(f'Loss: {results[0]:.4f}\\nAccuracy: {results[1]:.4f}')\n","    results = model.evaluate(test_generator,steps=2*len(test_generator),verbose=0)\n","    print('Evaluation Set:')\n","    print(f'Loss: {results[0]:.4f}\\nAccuracy: {results[1]: .4f}')\n","    print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 4816 images belonging to 2 classes.\n","Found 14090 images belonging to 2 classes.\n","\n","Model: mel_spec_model.h5\n","Development Set:\n","Loss: 0.0501\n","Accuracy: 0.9817\n","Evaluation Set:\n","Loss: 0.3875\n","Accuracy:  0.8914\n","\n","Found 4842 images belonging to 2 classes.\n","Found 14180 images belonging to 2 classes.\n","\n","Model: amp_plot_model.h5\n","Development Set:\n","Loss: 0.3834\n","Accuracy: 0.8088\n","Evaluation Set:\n","Loss: 0.3431\n","Accuracy:  0.8434\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"yN7ZuW8Afpko"},"source":["# **LSTM Approach**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fd6zY9UP2fd4","colab":{}},"source":["!cp drive/My\\ Drive/ASV/npys_32000.zip npys_32000.zip\n","!unzip npys_32000.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uQJKFp0MYNGL","colab":{}},"source":["dataset = 'npys_32000'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LL9J1C7EPoR-","colab":{}},"source":["def get_input(filepath):\n","    try:\n","        clip = np.load(filepath)\n","    except:\n","        print(filepath)\n","    sample_rate = 16000\n","    rmse = librosa.feature.rms(y=clip)\n","    chroma_stft = librosa.feature.chroma_stft(y=clip, sr=sample_rate)\n","    spec_cent = librosa.feature.spectral_centroid(y=clip, sr=sample_rate)\n","    spec_bw = librosa.feature.spectral_bandwidth(y=clip, sr=sample_rate)\n","    rolloff = librosa.feature.spectral_rolloff(y=clip, sr=sample_rate)\n","    zcr = librosa.feature.zero_crossing_rate(clip)\n","    mfcc = librosa.feature.mfcc(y=clip, sr=sample_rate)\n","    arr = np.concatenate([rmse,chroma_stft,spec_cent,spec_bw,rolloff,zcr,mfcc],axis=0).T\n","    arr = (arr - arr.mean(axis=0))/(arr.std(axis=0))\n","    return [arr]\n","\n","def data_generator(dataset, split = 'train', batch_size = 8):\n","\n","    assert batch_size % 2 == 0\n","    real_files = [f'{dataset}/{split}/real/{f}' for f in os.listdir(f'{dataset}/{split}/real') if '.ipynb' not in f]\n","    fake_files = [f'{dataset}/{split}/fake/{f}' for f in os.listdir(f'{dataset}/{split}/fake') if '.ipynb' not in f]\n","\n","    while True:\n","        real_batch_paths = np.random.choice(a = real_files, size = batch_size // 2)\n","        fake_batch_paths = np.random.choice(a = fake_files, size = batch_size // 2)\n","        batch_input  = []\n","        batch_output = []\n","\n","        for real_input_path, fake_input_path in zip(real_batch_paths, fake_batch_paths):\n","            batch_input += get_input(real_input_path)\n","            batch_input += get_input(fake_input_path)\n","            batch_output += [[0.],[1.]]\n","        # Return a tuple of (input, output) to feed the network\n","        batch_x = np.array(batch_input,dtype=np.float32)\n","        batch_y = np.array(batch_output,dtype=np.float32)\n","\n","        yield(batch_x, batch_y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sVKOSFa6Qk-r","colab":{}},"source":["batch_size = 32\n","dev_gen = data_generator(dataset, 'dev', batch_size = batch_size)\n","eval_gen = data_generator(dataset, 'eval', batch_size = batch_size)\n","dev_spe = len(os.listdir(f'{dataset}/dev/real'))//batch_size\n","eval_spe = len(os.listdir(f'{dataset}/eval/real'))//batch_size"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oUBqIeV8Rkoe","colab":{}},"source":["def lstm(input_shape = (None, 37), lr = 1e-3):\n","    inputs = layers.Input(input_shape)\n","    X = layers.LSTM(64, return_sequences=True)(inputs)\n","    X = layers.LSTM(64, return_sequences=True)(X)\n","    X = layers.Dropout(rate=0.5)(X)\n","    X = layers.LSTM(128, return_sequences=True)(X)\n","    X = layers.LSTM(128, return_sequences=True)(X)\n","    X = layers.Dropout(rate=0.5)(X)\n","    X = layers.LSTM(256, return_sequences=False)(X)\n","    X = layers.Dropout(rate=0.5)(X)\n","    X = layers.Dense(128, activation = 'relu')(X)\n","    X = layers.Dropout(rate=0.5)(X)\n","    X = layers.Dense(1)(X)\n","    X = layers.Activation('sigmoid', dtype='float32', name='predictions')(X)\n","    #X = layers.Dense(1, activation = 'sigmoid')(X)\n","    model = models.Model(inputs = inputs, outputs = X)\n","    model.compile(optimizer = Adam(lr), loss = 'binary_crossentropy', metrics = ['accuracy'])\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rZ5ZskRPRaH6","colab":{}},"source":["model = lstm()\n","model.load_weights('lstm_model.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5FhMzIT_R7mT","colab":{"base_uri":"https://localhost:8080/","height":153},"outputId":"b843a2db-f83c-45ac-bb74-151406bdef9c"},"source":["results = model.evaluate(dev_gen, verbose = 0, steps = 2*dev_spe)\n","print('Development Set:')\n","print(f'Loss: {results[0]:.4f}\\nAccuracy: {results[1]:.4f}')\n","results = model.evaluate(eval_gen, verbose = 0, steps = 2*eval_spe)\n","print('Evaluation Set:')\n","print(f'Loss: {results[0]:.4f}\\nAccuracy: {results[1]:.4f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/librosa/core/pitch.py:145: UserWarning: Trying to estimate tuning from empty frequency set.\n","  warnings.warn('Trying to estimate tuning from empty frequency set.')\n"],"name":"stderr"},{"output_type":"stream","text":["Development Set:\n","Loss: 0.3529\n","Accuracy: 0.8687\n","Evaluation Set:\n","Loss: 0.5216\n","Accuracy: 0.8333\n"],"name":"stdout"}]}]}