{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X73ugMB0QB89"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "import librosa\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EWKM_YJPsbiU"
   },
   "outputs": [],
   "source": [
    "dataset = 'npys_32000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-jTi6Xn2NOD"
   },
   "outputs": [],
   "source": [
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oc8oMEqwXQZg"
   },
   "outputs": [],
   "source": [
    "def lstm(input_shape = (None, 37), lr = 1e-3):\n",
    "    inputs = layers.Input(input_shape)\n",
    "    X = layers.LSTM(64, return_sequences=True)(inputs)\n",
    "    X = layers.LSTM(64, return_sequences=True)(X)\n",
    "    X = layers.Dropout(rate=0.5)(X)\n",
    "    X = layers.LSTM(128, return_sequences=True)(X)\n",
    "    X = layers.LSTM(128, return_sequences=True)(X)\n",
    "    X = layers.Dropout(rate=0.5)(X)\n",
    "    X = layers.LSTM(256, return_sequences=False)(X)\n",
    "    X = layers.Dropout(rate=0.5)(X)\n",
    "    X = layers.Dense(128, activation = 'relu')(X)\n",
    "    X = layers.Dropout(rate=0.5)(X)\n",
    "    X = layers.Dense(1)(X)\n",
    "    X = layers.Activation('sigmoid', dtype='float32', name='predictions')(X)\n",
    "    model = models.Model(inputs = inputs, outputs = X)\n",
    "    model.compile(optimizer = Adam(lr), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y4u93cXAOFWT"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XfMc25UlmVWc"
   },
   "outputs": [],
   "source": [
    "def get_input(filepath):\n",
    "    clip = np.load(filepath)\n",
    "    sample_rate = 16000\n",
    "    rmse = librosa.feature.rms(y=clip)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=clip, sr=sample_rate)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=clip, sr=sample_rate)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=clip, sr=sample_rate)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=clip, sr=sample_rate)\n",
    "    zcr = librosa.feature.zero_crossing_rate(clip)\n",
    "    mfcc = librosa.feature.mfcc(y=clip, sr=sample_rate)\n",
    "    arr = np.concatenate([rmse,chroma_stft,spec_cent,spec_bw,rolloff,zcr,mfcc],axis=0).T\n",
    "    # Do either\n",
    "    # 1. Normalise\n",
    "    #arr = (arr - arr.min(axis=0))/(arr.max(axis=0)-arr.min(axis=0))\n",
    "    # 2. Standardise\n",
    "    arr = (arr - arr.mean(axis=0))/(arr.std(axis=0))\n",
    "    # 3. Standardise then divide\n",
    "    #arr = arr/arr.max(axis=0)\n",
    "    # 4. Normalise in [-1,1]\n",
    "    #arr = 2*(arr - arr.min(axis=0))/(arr.max(axis=0)-arr.min(axis=0)) - 1\n",
    "    return [arr]\n",
    "\n",
    "def data_generator(dataset, split = 'train', batch_size = 8):\n",
    "\n",
    "    assert batch_size % 2 == 0\n",
    "    real_files = [f'{dataset}/{split}/real/{f}' for f in os.listdir(f'{dataset}/{split}/real') if '.ipynb' not in f]\n",
    "    fake_files = [f'{dataset}/{split}/fake/{f}' for f in os.listdir(f'{dataset}/{split}/fake') if '.ipynb' not in f]\n",
    "\n",
    "    while True:\n",
    "        real_batch_paths = np.random.choice(a = real_files, size = batch_size // 2)\n",
    "        fake_batch_paths = np.random.choice(a = fake_files, size = batch_size // 2)\n",
    "        batch_input  = []\n",
    "        batch_output = []\n",
    "\n",
    "        for real_input_path, fake_input_path in zip(real_batch_paths, fake_batch_paths):\n",
    "            batch_input += get_input(real_input_path)\n",
    "            batch_input += get_input(fake_input_path)\n",
    "            batch_output += [[0.],[1.]]\n",
    "        # Return a tuple of (input, output) to feed the network\n",
    "        batch_x = np.array(batch_input,dtype=np.float32)\n",
    "        batch_y = np.array(batch_output,dtype=np.float32)\n",
    "\n",
    "        yield(batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UQHDn-SGpHYJ"
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FVDnYK0Eo-5f"
   },
   "outputs": [],
   "source": [
    "train_gen = data_generator(dataset, 'train', batch_size = batch_size)\n",
    "dev_gen = data_generator(dataset, 'dev', batch_size = batch_size)\n",
    "eval_gen = data_generator(dataset, 'eval', batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6ysUoe__qoen",
    "outputId": "9a600848-ce9a-453b-e433-5d34765c20cf"
   },
   "outputs": [],
   "source": [
    "train_spe = len(os.listdir(f'{dataset}/train/real'))//batch_size\n",
    "dev_spe = len(os.listdir(f'{dataset}/dev/real'))//batch_size\n",
    "eval_spe = len(os.listdir(f'{dataset}/eval/real'))//batch_size\n",
    "print(train_spe, dev_spe, eval_spe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "id": "HwXnTRutJcOp",
    "outputId": "5b098336-d4c7-4641-d29e-8238f4fee524"
   },
   "outputs": [],
   "source": [
    "x,y = next(train_gen)\n",
    "pd.options.display.float_format = '{:,.6f}'.format\n",
    "pd.DataFrame(x[0]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wKip-jcjx4Cj"
   },
   "outputs": [],
   "source": [
    "clip = np.load('npys_32000/train/real/LA_T_3565683.npy')\n",
    "sample_rate = 16000\n",
    "rmse = librosa.feature.rms(y=clip)\n",
    "chroma_stft = librosa.feature.chroma_stft(y=clip, sr=sample_rate)\n",
    "spec_cent = librosa.feature.spectral_centroid(y=clip, sr=sample_rate)\n",
    "spec_bw = librosa.feature.spectral_bandwidth(y=clip, sr=sample_rate)\n",
    "rolloff = librosa.feature.spectral_rolloff(y=clip, sr=sample_rate)\n",
    "zcr = librosa.feature.zero_crossing_rate(clip)\n",
    "mfcc = librosa.feature.mfcc(y=clip, sr=sample_rate)\n",
    "arr = np.concatenate([rmse,chroma_stft,spec_cent,spec_bw,rolloff,zcr,mfcc],axis=0).T\n",
    "# Normalise\n",
    "arr = (arr - arr.min(axis=0))/(arr.max(axis=0)-arr.min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnP7htJmqSzZ"
   },
   "outputs": [],
   "source": [
    "model_path = f'models/{dataset}'\n",
    "Path(model_path).mkdir(parents=True, exist_ok = True)\n",
    "checkpointer = ModelCheckpoint(model_path+f'/{dataset}_lstm_standardised_'+'epochs:{epoch:02d}_acc:{val_accuracy:.4f}.h5', monitor = 'val_loss', save_best_only = True, verbose = 1, mode = 'min')\n",
    "earlystopper = EarlyStopping(monitor = 'val_loss', patience = 5, verbose = 1, mode = 'min')\n",
    "reduceLR = ReduceLROnPlateau(monitor = 'val_loss', factor = 1/np.sqrt(10), patience = 3, cooldown = 1, verbose = 1, mode = 'min')\n",
    "model = lstm()\n",
    "history = model.fit(train_gen, steps_per_epoch = train_spe, verbose = 1, epochs = 50, callbacks = [checkpointer, earlystopper, reduceLR], validation_data=dev_gen, validation_steps = dev_spe)\n",
    "print(model.evaluate(eval_gen, steps = eval_spe))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ASV_LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
