{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"},"colab":{"name":"training.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"37qCDATIGcT2","colab_type":"text"},"source":["# **Training in Keras**"]},{"cell_type":"markdown","metadata":{"id":"jqZKdInzGmoP","colab_type":"text"},"source":["Install Keras"]},{"cell_type":"code","metadata":{"id":"McZVWJEhF3dl","colab_type":"code","colab":{}},"source":["!pip install keras"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DzMrmRvHGpbJ","colab_type":"text"},"source":["Import necessary packages"]},{"cell_type":"code","metadata":{"id":"EcpRgyLWF3dq","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import os\n","from matplotlib import pyplot as plt\n","import numpy as np\n","from keras import layers, models\n","from keras_preprocessing.image import ImageDataGenerator\n","from keras.optimizers import Adam\n","from keras.callbacks import ModelCheckpoint\n","from keras.models import load_model\n","from keras.utils import multi_gpu_model\n","from keras.backend.tensorflow_backend import set_session\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wLoRaIJKGtCE","colab_type":"text"},"source":["Enable allow_growth on Keras"]},{"cell_type":"code","metadata":{"id":"MTHMhximF3dt","colab_type":"code","colab":{}},"source":["config = tf.ConfigProto()\n","config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n","config.log_device_placement = True  # to log device placement (on which device the operation ran)\n","sess = tf.Session(config=config)\n","set_session(sess)  # set this TensorFlow session as the default session for Keras"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YB_FwqdiGxMr","colab_type":"text"},"source":["Define Xception Model Architecture"]},{"cell_type":"code","metadata":{"id":"zzsnE7FNF3dx","colab_type":"code","colab":{}},"source":["def Xception(input_shape=(128,128,3)):\n","    channel_axis = 3\n","    img_input = layers.Input(input_shape)\n","    \n","    x = layers.Conv2D(32, (3, 3),\n","                      strides=(2, 2),\n","                      use_bias=False,\n","                      name='block1_conv1')(img_input)\n","    x = layers.BatchNormalization(axis=channel_axis, name='block1_conv1_bn')(x)\n","    x = layers.Activation('relu', name='block1_conv1_act')(x)\n","    x = layers.Conv2D(64, (3, 3), use_bias=False, name='block1_conv2')(x)\n","    x = layers.BatchNormalization(axis=channel_axis, name='block1_conv2_bn')(x)\n","    x = layers.Activation('relu', name='block1_conv2_act')(x)\n","\n","    residual = layers.Conv2D(128, (1, 1),\n","                             strides=(2, 2),\n","                             padding='same',\n","                             use_bias=False)(x)\n","    residual = layers.BatchNormalization(axis=channel_axis)(residual)\n","\n","    x = layers.SeparableConv2D(128, (3, 3),\n","                               padding='same',\n","                               use_bias=False,\n","                               name='block2_sepconv1')(x)\n","    x = layers.BatchNormalization(axis=channel_axis, name='block2_sepconv1_bn')(x)\n","    x = layers.Activation('relu', name='block2_sepconv2_act')(x)\n","    x = layers.SeparableConv2D(128, (3, 3),\n","                               padding='same',\n","                               use_bias=False,\n","                               name='block2_sepconv2')(x)\n","    x = layers.BatchNormalization(axis=channel_axis, name='block2_sepconv2_bn')(x)\n","\n","    x = layers.MaxPooling2D((3, 3),\n","                            strides=(2, 2),\n","                            padding='same',\n","                            name='block2_pool')(x)\n","    x = layers.add([x, residual])\n","\n","    residual = layers.Conv2D(256, (1, 1), strides=(2, 2),\n","                             padding='same', use_bias=False)(x)\n","    residual = layers.BatchNormalization(axis=channel_axis)(residual)\n","\n","    x = layers.Activation('relu', name='block3_sepconv1_act')(x)\n","    x = layers.SeparableConv2D(256, (3, 3),\n","                               padding='same',\n","                               use_bias=False,\n","                               name='block3_sepconv1')(x)\n","    x = layers.BatchNormalization(axis=channel_axis, name='block3_sepconv1_bn')(x)\n","    x = layers.Activation('relu', name='block3_sepconv2_act')(x)\n","    x = layers.SeparableConv2D(256, (3, 3),\n","                               padding='same',\n","                               use_bias=False,\n","                               name='block3_sepconv2')(x)\n","    x = layers.BatchNormalization(axis=channel_axis, name='block3_sepconv2_bn')(x)\n","\n","    x = layers.MaxPooling2D((3, 3), strides=(2, 2),\n","                            padding='same',\n","                            name='block3_pool')(x)\n","    x = layers.add([x, residual])\n","\n","    residual = layers.Conv2D(728, (1, 1),\n","                             strides=(2, 2),\n","                             padding='same',\n","                             use_bias=False)(x)\n","    residual = layers.BatchNormalization(axis=channel_axis)(residual)\n","\n","    x = layers.Activation('relu', name='block4_sepconv1_act')(x)\n","    x = layers.SeparableConv2D(728, (3, 3),\n","                               padding='same',\n","                               use_bias=False,\n","                               name='block4_sepconv1')(x)\n","    x = layers.BatchNormalization(axis=channel_axis, name='block4_sepconv1_bn')(x)\n","    x = layers.Activation('relu', name='block4_sepconv2_act')(x)\n","    x = layers.SeparableConv2D(728, (3, 3),\n","                               padding='same',\n","                               use_bias=False,\n","                               name='block4_sepconv2')(x)\n","    x = layers.BatchNormalization(axis=channel_axis, name='block4_sepconv2_bn')(x)\n","\n","    x = layers.MaxPooling2D((3, 3), strides=(2, 2),\n","                            padding='same',\n","                            name='block4_pool')(x)\n","    x = layers.add([x, residual])\n","\n","    for i in range(8):\n","        residual = x\n","        prefix = 'block' + str(i + 5)\n","\n","        x = layers.Activation('relu', name=prefix + '_sepconv1_act')(x)\n","        x = layers.SeparableConv2D(728, (3, 3),\n","                                   padding='same',\n","                                   use_bias=False,\n","                                   name=prefix + '_sepconv1')(x)\n","        x = layers.BatchNormalization(axis=channel_axis,\n","                                      name=prefix + '_sepconv1_bn')(x)\n","        x = layers.Activation('relu', name=prefix + '_sepconv2_act')(x)\n","        x = layers.SeparableConv2D(728, (3, 3),\n","                                   padding='same',\n","                                   use_bias=False,\n","                                   name=prefix + '_sepconv2')(x)\n","        x = layers.BatchNormalization(axis=channel_axis,\n","                                      name=prefix + '_sepconv2_bn')(x)\n","        x = layers.Activation('relu', name=prefix + '_sepconv3_act')(x)\n","        x = layers.SeparableConv2D(728, (3, 3),\n","                                   padding='same',\n","                                   use_bias=False,\n","                                   name=prefix + '_sepconv3')(x)\n","        x = layers.BatchNormalization(axis=channel_axis,\n","                                      name=prefix + '_sepconv3_bn')(x)\n","\n","        x = layers.add([x, residual])\n","\n","    residual = layers.Conv2D(1024, (1, 1), strides=(2, 2),\n","                             padding='same', use_bias=False)(x)\n","    residual = layers.BatchNormalization(axis=channel_axis)(residual)\n","\n","    x = layers.Activation('relu', name='block13_sepconv1_act')(x)\n","    x = layers.SeparableConv2D(728, (3, 3),\n","                               padding='same',\n","                               use_bias=False,\n","                               name='block13_sepconv1')(x)\n","    x = layers.BatchNormalization(axis=channel_axis, name='block13_sepconv1_bn')(x)\n","    x = layers.Activation('relu', name='block13_sepconv2_act')(x)\n","    x = layers.SeparableConv2D(1024, (3, 3),\n","                               padding='same',\n","                               use_bias=False,\n","                               name='block13_sepconv2')(x)\n","    x = layers.BatchNormalization(axis=channel_axis, name='block13_sepconv2_bn')(x)\n","\n","    x = layers.MaxPooling2D((3, 3),\n","                            strides=(2, 2),\n","                            padding='same',\n","                            name='block13_pool')(x)\n","    x = layers.add([x, residual])\n","\n","    x = layers.SeparableConv2D(1536, (3, 3),\n","                               padding='same',\n","                               use_bias=False,\n","                               name='block14_sepconv1')(x)\n","    x = layers.BatchNormalization(axis=channel_axis, name='block14_sepconv1_bn')(x)\n","    x = layers.Activation('relu', name='block14_sepconv1_act')(x)\n","\n","    x = layers.SeparableConv2D(2048, (3, 3),\n","                               padding='same',\n","                               use_bias=False,\n","                               name='block14_sepconv2')(x)\n","    x = layers.BatchNormalization(axis=channel_axis, name='block14_sepconv2_bn')(x)\n","    x = layers.Activation('relu', name='block14_sepconv2_act')(x)\n","\n","    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n","    x = layers.Dense(1, activation='sigmoid', name='predictions')(x)\n","\n","    inputs = img_input\n","    \n","    model = models.Model(inputs, x, name='xception')\n","    \n","    # Uncomment below line for multi GPU training\n","    # model = multi_gpu_model(model, gpus = num_gpus)\n","    \n","    model.compile(optimizer = Adam(), loss = 'binary_crossentropy', metrics = ['accuracy'])\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F2v414GjHfBd","colab_type":"text"},"source":["Add dataset path and define parameters"]},{"cell_type":"code","metadata":{"id":"gc_eqzLGF3dz","colab_type":"code","colab":{}},"source":["dataset = 'YOUR DATASET PATH'\n","assert dataset[-1] == '/'\n","img_shape = 128\n","num_channels = 3\n","color = 'rgb'\n","epochs = 20\n","batch_size = 32\n","\n","# If multi GPU training, uncomment and add number of GPUs below\n","# num_gpus = "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7CLca7rCHmrH","colab_type":"text"},"source":["Create Xception model"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"uI-jxcOeF3d2","colab_type":"code","colab":{}},"source":["model = Xception(input_shape=(img_shape, img_shape, num_channels))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vc1OiWrtF3d4","colab_type":"code","colab":{}},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QQBwyiP8HrOX","colab_type":"text"},"source":["Data Preprocessing"]},{"cell_type":"code","metadata":{"id":"FFfhzGf4F3d7","colab_type":"code","colab":{}},"source":["datagen = ImageDataGenerator(rescale = 1/255)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"kxm0OOvzF3d-","colab_type":"code","colab":{}},"source":["# We create a three way train test val split\n","train_it = datagen.flow_from_directory(dataset+'train/', color_mode= color, classes=['real','fake'], target_size=(img_shape, img_shape), class_mode='binary', batch_size=batch_size, interpolation = 'bicubic', seed = 2048)\n","val_it = datagen.flow_from_directory(dataset+'val/', color_mode= color, classes=['real','fake'], target_size=(img_shape, img_shape), class_mode='binary', batch_size=batch_size, interpolation = 'bicubic', seed = 2048)\n","test_it = datagen.flow_from_directory(dataset+'test/', color_mode= color, classes=['real','fake'], target_size=(img_shape, img_shape), class_mode='binary', batch_size=batch_size, interpolation = 'bicubic', seed = 2048)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3tXiGWMrJZeY","colab_type":"text"},"source":["Create checkpoints and add them to your callbacks"]},{"cell_type":"code","metadata":{"id":"Q1sixfH2F3eF","colab_type":"code","colab":{}},"source":["# Add checkpoint path below\n","checkpoint_path = '*YOUR CHECKPOINT FOLDER GOES HERE* /cp-{epoch:04d}.h5'\n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","# Create a callback that saves the model after each epoch\n","checkpoint = ModelCheckpoint(filepath=checkpoint_path, save_best_only=False, verbose=1)\n","callbacks_list = [checkpoint]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FNdxbqjaJhIK","colab_type":"text"},"source":["Begin training of model"]},{"cell_type":"code","metadata":{"id":"-V368CHZJfQy","colab_type":"code","colab":{}},"source":["# This may generate warnings related to saving the state of the optimizer.\n","# These warnings (and similar warnings throughout this notebook)\n","# are in place to discourage outdated usage, and can be ignored.\n","history = model.fit_generator(generator = train_it, validation_data = val_it, epochs = epochs, callbacks=callbacks_list, verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0IzSvnj5Jwg9","colab_type":"text"},"source":["List all data in History"]},{"cell_type":"code","metadata":{"id":"-OUItIEuF3eH","colab_type":"code","colab":{}},"source":["print(history.history.keys())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iTSaOju9J0ST","colab_type":"text"},"source":["Plot training & validation accuracy curves"]},{"cell_type":"code","metadata":{"id":"tycDyxHxF3eL","colab_type":"code","colab":{}},"source":["plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Model accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Test'], loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UEE-cGr4J6Hm","colab_type":"text"},"source":["Plot training & validation loss curves"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"osn86B8DF3eN","colab_type":"code","colab":{}},"source":["plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Test'], loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8Vxt0YkQKqPV","colab_type":"text"},"source":["Evaluation of Model on Test set"]},{"cell_type":"code","metadata":{"id":"7ibgon28F3eP","colab_type":"code","colab":{}},"source":["# Add the path of model you wish to evaluate\n","model = load_model('YOUR MODEL PATH')\n","loss = model.evaluate_generator(test_it, verbose = 1)"],"execution_count":null,"outputs":[]}]}